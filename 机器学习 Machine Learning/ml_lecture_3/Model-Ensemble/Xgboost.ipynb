{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大杀器Xgboost入门\n",
    "by 寒小阳(hanxiaoyang.ml@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.数据读取与简单建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.042831\ttrain-error:0.046522\n",
      "[1]\teval-error:0.021726\ttrain-error:0.022263\n",
      "error=0.021726\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "### simple example\n",
    "# load file from text file, also binary buffer generated by xgboost\n",
    "dtrain = xgb.DMatrix('data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('data/agaricus.txt.test')\n",
    "\n",
    "# specify parameters via map, definition are same as c++ version\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "\n",
    "# specify validations set to watch performance\n",
    "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "\n",
    "# this is prediction\n",
    "preds = bst.predict(dtest)\n",
    "labels = dtest.get_label()\n",
    "print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dmatrix into binary buffer\n",
    "dtest.save_binary('dtest.buffer')\n",
    "# save model\n",
    "bst.save_model('xgb.model')\n",
    "# load model and data in\n",
    "bst2 = xgb.Booster(model_file='xgb.model')\n",
    "dtest2 = xgb.DMatrix('dtest.buffer')\n",
    "preds2 = bst2.predict(dtest2)\n",
    "# assert they are the same\n",
    "assert np.sum(np.abs(preds2-preds)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation\n",
      "[0]\ttrain-error:0.0506912+0.00919397\ttest-error:0.0557604+0.0158272\n",
      "[1]\ttrain-error:0.0213132+0.00207524\ttest-error:0.0211982+0.00381269\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.009194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>0.002075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "0         0.055760        0.015827          0.050691         0.009194\n",
       "1         0.021198        0.003813          0.021313         0.002075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "### load data in do training\n",
    "dtrain = xgb.DMatrix('data/agaricus.txt.train')\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "num_round = 2\n",
    "\n",
    "print ('running cross validation')\n",
    "# do cross validation, this will print result out as\n",
    "# [iteration]  metric_name:mean_value+std_value\n",
    "# std_value is standard deviation of the metric\n",
    "xgb.cv(param, dtrain, num_round, nfold=5,\n",
    "       metrics={'error'}, seed = 0,\n",
    "       callbacks=[xgb.callback.print_evaluation(show_stdv=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation, disable standard deviation display\n",
      "[0]\ttrain-error:0.0506912\ttest-error:0.0557604\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 3 rounds.\n",
      "[1]\ttrain-error:0.0213132\ttest-error:0.0211982\n",
      "[2]\ttrain-error:0.0099458\ttest-error:0.0099844\n",
      "[3]\ttrain-error:0.0141322\ttest-error:0.0144392\n",
      "[4]\ttrain-error:0.0059904\ttest-error:0.0062978\n",
      "[5]\ttrain-error:0.0020352\ttest-error:0.0016896\n",
      "[6]\ttrain-error:0.0012288\ttest-error:0.0012288\n",
      "[7]\ttrain-error:0.0012288\ttest-error:0.0012288\n",
      "[8]\ttrain-error:0.0009216\ttest-error:0.0012288\n",
      "[9]\ttrain-error:0.0006144\ttest-error:0.0012288\n",
      "Stopping. Best iteration:\n",
      "[6]\ttrain-error:0.0012288+0.000260441\ttest-error:0.0012288+0.00104177\n",
      "\n",
      "   test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      "0         0.055760        0.015827          0.050691         0.009194\n",
      "1         0.021198        0.003813          0.021313         0.002075\n",
      "2         0.009984        0.004784          0.009946         0.006076\n",
      "3         0.014439        0.003616          0.014132         0.001720\n",
      "4         0.006298        0.003049          0.005990         0.001871\n",
      "5         0.001690        0.000575          0.002035         0.001470\n",
      "6         0.001229        0.001042          0.001229         0.000260\n"
     ]
    }
   ],
   "source": [
    "print ('running cross validation, disable standard deviation display')\n",
    "# do cross validation, this will print result out as\n",
    "# [iteration]  metric_name:mean_value\n",
    "res = xgb.cv(param, dtrain, num_boost_round=10, nfold=5,\n",
    "             metrics={'error'}, seed = 0,\n",
    "             callbacks=[xgb.callback.print_evaluation(show_stdv=False),\n",
    "                        xgb.callback.early_stop(3)])\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation, with preprocessing function\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958198</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.958196</td>\n",
       "      <td>0.001377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981412</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.981403</td>\n",
       "      <td>0.000655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
       "0       0.958198      0.005520        0.958196       0.001377\n",
       "1       0.981412      0.002618        0.981403       0.000655"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('running cross validation, with preprocessing function')\n",
    "# define the preprocessing function\n",
    "# used to return the preprocessed training, test data, and parameter\n",
    "# we can use this to do weight rescale, etc.\n",
    "# as a example, we try to set scale_pos_weight\n",
    "def fpreproc(dtrain, dtest, param):\n",
    "    label = dtrain.get_label()\n",
    "    ratio = float(np.sum(label == 0)) / np.sum(label==1)\n",
    "    param['scale_pos_weight'] = ratio\n",
    "    return (dtrain, dtest, param)\n",
    "\n",
    "# do cross validation, for each fold\n",
    "# the dtrain, dtest, param will be passed into fpreproc\n",
    "# then the return value of fpreproc will be used to generate\n",
    "# results of that fold\n",
    "xgb.cv(param, dtrain, num_round, nfold=5,\n",
    "       metrics={'auc'}, seed = 0, fpreproc = fpreproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation, with cutomsized loss function\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>1.597543</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>1.594790</td>\n",
       "      <td>0.003879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>2.448759</td>\n",
       "      <td>0.080213</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>2.442099</td>\n",
       "      <td>0.076912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-error-mean  test-error-std  test-rmse-mean  test-rmse-std  \\\n",
       "0         0.055760        0.015827        1.597543       0.012465   \n",
       "1         0.021198        0.003813        2.448759       0.080213   \n",
       "\n",
       "   train-error-mean  train-error-std  train-rmse-mean  train-rmse-std  \n",
       "0          0.050691         0.009194         1.594790        0.003879  \n",
       "1          0.021313         0.002075         2.442099        0.076912  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# you can also do cross validation with cutomized loss function\n",
    "# See custom_objective.py\n",
    "##\n",
    "print ('running cross validation, with cutomsized loss function')\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    return grad, hess\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'error', float(sum(labels != (preds > 0.0))) / len(labels)\n",
    "\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1}\n",
    "# train with customized objective\n",
    "xgb.cv(param, dtrain, num_round, nfold = 5, seed = 0,\n",
    "       obj = logregobj, feval=evalerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.网格搜索与交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 见参数调优ipython notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
